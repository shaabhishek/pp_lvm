{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module name here\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder_h(nn.Module):\n",
    "    def __init__(self, Y_dim, H_dim, hidden_dim = 16):\n",
    "        super().__init__()\n",
    "        self.make_encoder(Y_dim, H_dim, hidden_dim)\n",
    "  \n",
    "    def make_encoder(self, Y_dim, H_dim, hidden_dim):\n",
    "        self.net = nn.Sequential(nn.Linear(Y_dim, hidden_dim), nn.Tanh(), nn.Linear(hidden_dim, hidden_dim), nn.Tanh())\n",
    "        self.mu = nn.Linear(hidden_dim, H_dim)\n",
    "        self.std = nn.Sequential(nn.Linear(hidden_dim, H_dim), nn.Softplus())\n",
    "  \n",
    "    def forward(self, y):\n",
    "        hidden_state = self.net(y)\n",
    "        mu, std = self.mu(hidden_state), self.std(hidden_state)\n",
    "        return dist.Normal(mu, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder_h(nn.Module):\n",
    "    def __init__(self, B, H_dim):\n",
    "        super().__init__()\n",
    "        self.B = B\n",
    "        self.H_dim = H_dim\n",
    "        self.make_parameters()\n",
    "\n",
    "    def make_parameters(self):\n",
    "        self.mu = nn.Linear(self.H_dim, self.B, bias=False) #Just the matrix\n",
    "        self.sigma = nn.Linear(self.H_dim, self.B, bias=False) #Just the matrix\n",
    "        torch.nn.init.uniform_(self.sigma.weight, a=1.0, b=2.0)\n",
    "#         self.mu = nn.Parameter(torch.randn(self.B, self.H_dim))\n",
    "#         sigma = torch.rand(self.B, self.H_dim).view(self.B, self.H_dim) * torch.randint(1,10, (1,), dtype=torch.float32)\n",
    "#         self.sigma = nn.Parameter(sigma)\n",
    "\n",
    "    def _log_likelihood(self, h):\n",
    "        \"\"\"\n",
    "        h: shape=(BS,N,H_dim)\n",
    "        \"\"\"\n",
    "        BS, S, H_dim = h.shape\n",
    "        return dist.Normal(self.mu.weight.view(1,1,self.B,H_dim), self.sigma.weight.view(1,1,self.B,self.H_dim)).log_prob(h.view(BS, S, 1, H_dim))\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        z: shape = (BS,N) or (BS,) or (1,)\n",
    "        \"\"\"\n",
    "        # print(z_n)\n",
    "        h_dist = dist.Normal(self.mu.weight[z], self.sigma.weight[z])\n",
    "        return h_dist.rsample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder_x(nn.Module):\n",
    "    def __init__(self, I_dim, H_dim, X_dim, hidden_size=16, inducing_point_stride=None):\n",
    "        super().__init__()\n",
    "        self.inducing_point_stride = inducing_point_stride\n",
    "        self.hidden_size = hidden_size\n",
    "        self.make_network(I_dim, H_dim, X_dim, hidden_size)\n",
    "\n",
    "    def make_network(self, I_dim, H_dim, X_dim, hidden_size):\n",
    "        self.bilstm = nn.LSTM(input_size=I_dim+H_dim, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n",
    "        # self.densenet = nn.Sequential(nn.Linear(2*hidden_size, X_dim), nn.ReLU())\n",
    "        self.mu = nn.Linear(2*hidden_size, X_dim)\n",
    "        self.sigma = nn.Sequential(nn.Linear(2*hidden_size, X_dim), nn.Softplus())\n",
    "  \n",
    "    def forward(self, i_seq, h_seq):\n",
    "        \"\"\"\n",
    "        i_seq: shape = (BS, N)\n",
    "        h_seq: shape = (BS, N, H_dim)\n",
    "        \"\"\"\n",
    "        BS, T = i_seq.shape\n",
    "        assert(len(i_seq.shape)==2)\n",
    "        lstm_input = torch.cat([i_seq.view(*i_seq.shape, 1), h_seq], dim=-1)\n",
    "        hidden, _ = self.bilstm(lstm_input) #shape(hidden) = (BS, N, 2*hidden_size)\n",
    "    \n",
    "        if self.inducing_point_stride is not None:\n",
    "            mu, sigma = self.mu(hidden[:, ::self.inducing_point_stride]), self.sigma(hidden[:, ::self.inducing_point_stride])\n",
    "        else:\n",
    "            mu, sigma = self.mu(hidden), self.sigma(hidden)\n",
    "        return dist.Normal(mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Model_z(nn.Module):\n",
    "    def __init__(self, B, debug=False):\n",
    "        super().__init__()\n",
    "        self.B = B\n",
    "        self.make_parameters(debug=debug)\n",
    "    \n",
    "    def make_parameters(self, X_dim = 1, debug=False):\n",
    "        self.Wx = nn.Linear(X_dim, self.B, bias=False)\n",
    "        # not a good idea: the norm is very high this way\n",
    "#         if debug:\n",
    "#             with torch.no_grad():\n",
    "#                 self.Wx.weight.copy_(Params.Wx.view(*self.Wx.weight.shape))\n",
    "        self.P = nn.Parameter((torch.rand((self.B,self.B)) + torch.eye(self.B,self.B)))\n",
    "        self.logpi = nn.Parameter(torch.rand((1,self.B)))\n",
    "    \n",
    "    def transform_x(self, x):\n",
    "        \"\"\"\n",
    "        x: shape=(BS,N)\n",
    "        \"\"\"\n",
    "        x = x.view(*x.shape, 1) #shape=(BS,N,1)\n",
    "        return self.Wx(x)\n",
    "    \n",
    "    def forward(self, x, z_prev):\n",
    "        \"\"\"\n",
    "        x: shape=(BS,N)\n",
    "        z_prev: shape=(BS,N)\n",
    "        \"\"\"\n",
    "        logits = self.transform_x(x_n) + self.P[z_prev] #shape=(BS,N,B)\n",
    "        dist_z = dist.Categorical(logits=logits)\n",
    "        return dist_z.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder_i(nn.Module):\n",
    "    def __init__(self, X_dim, B):\n",
    "        super().__init__()\n",
    "        self.B = B\n",
    "        self.make_parameters(X_dim, B)\n",
    "\n",
    "    def make_parameters(self, X_dim, B):\n",
    "        # self.beta_a = nn.Parameter(torch.randn(X_dim + B + 1))\n",
    "        # self.beta_b = nn.Parameter(torch.randn(X_dim + B + 1))\n",
    "        self.glm = nn.Linear(X_dim + B, 2)\n",
    "\n",
    "    def _make_one_hot(self, z_n):\n",
    "        return F.one_hot(z_n, num_classes=self.B).float()\n",
    "\n",
    "    def _log_likelihood(self, i_n, x_n, z_n):\n",
    "        \"\"\"\n",
    "        i_n: shape=(BS,N)\n",
    "        x_n: shape=(BS,N)\n",
    "        z_n: shape=(BS,N)\n",
    "        \"\"\"\n",
    "        # BS, S = i_n.shape\n",
    "        dist_i = self._forward(x_n, z_n)\n",
    "        return dist_i.log_prob(i_n)\n",
    "    \n",
    "    def _forward(self, x_n, z_n):\n",
    "        \"\"\"\n",
    "        x_n - shape=(BS,N)\n",
    "        z_n - shape=(BS,N)\n",
    "        \"\"\"\n",
    "        x_n = x_n.view(*x_n.shape, 1) #shape = (BS,N,1)\n",
    "        z_n_one_hot = self._make_one_hot(z_n) #shape= (BS,N,B)\n",
    "        glm_input = torch.cat([x_n, z_n_one_hot], dim=-1)\n",
    "        gamma_params = self.glm(glm_input).mul(-1).exp() #shape= (BS,N,2)\n",
    "        num_dims = len(gamma_params.shape)\n",
    "        # from docs: tensor.select(0, index) is equivalent to tensor[index] and tensor.select(2, index) is equivalent to tensor[:,:,index].\n",
    "        a, b = gamma_params.select(num_dims-1, 0), gamma_params.select(num_dims-1, 1)\n",
    "        # gamma_params[*prev_shape,0], gamma_params[*prev_shape,1]\n",
    "        dist_i = dist.Gamma(a, b)\n",
    "        return dist_i\n",
    "\n",
    "    def forward(self, x_n, z_n):\n",
    "        \"\"\"\n",
    "        x_n - shape=(BS,N)\n",
    "        z_n - shape=(BS,N)\n",
    "        \"\"\"\n",
    "        # print(x_n.shape, z_n.shape)\n",
    "\n",
    "\n",
    "        # old code\n",
    "        # glm_input = torch.cat([torch.ones(*x_n.shape, 1), x_n, z_n_one_hot], dim=-1)\n",
    "        # a = torch.dot(self.beta_a, glm_input)\n",
    "        # b = torch.dot(self.beta_b, glm_input)\n",
    "\n",
    "        # new way - using matrix multiplication\n",
    "        dist_i = self._forward(x_n, z_n)\n",
    "        return dist_i.rsample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder_y(nn.Module):\n",
    "    def __init__(self, H_dim, Y_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.make_parameters(H_dim, Y_dim, hidden_dim)\n",
    "    \n",
    "    def make_parameters(self, H_dim, Y_dim, hidden_dim):\n",
    "        self.base_net = nn.Sequential(nn.Linear(H_dim, hidden_dim), nn.Tanh(), nn.Linear(hidden_dim, hidden_dim), nn.Tanh())\n",
    "        self.mu = nn.Linear(hidden_dim, Y_dim)\n",
    "        self.std = nn.Sequential(nn.Linear(hidden_dim, Y_dim), nn.Softplus())\n",
    "        \n",
    "    def _log_likelihood(self, H, Y):\n",
    "        \"\"\"\n",
    "        H: shape=(BS,N,H_dim)\n",
    "        Y: shape=(BS,N,Y_dim)\n",
    "        \"\"\"\n",
    "        BS, S, Y_dim = Y.shape\n",
    "        dist_Y = self.forward(H)\n",
    "        return dist_Y.log_prob(Y)\n",
    "    \n",
    "    def forward(self, H):\n",
    "        \"\"\"\n",
    "        H: shape=(BS,N,H_dim)\n",
    "        \"\"\"\n",
    "        hidden = self.base_net(H)\n",
    "        mu, std = self.mu(hidden), self.std(hidden)\n",
    "        dist_Y = dist.Normal(mu, std)\n",
    "        return dist_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message passing routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $l_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def l_n_vectorized(I, X, H, B, model_i, model_h, device):\n",
    "    \"\"\"\n",
    "    I: shape=(BS,N)\n",
    "    X: shape=(BS,N)\n",
    "    H: shape=(BS,N,H_dim)\n",
    "    device: 'cuda'/'cpu'\n",
    "\n",
    "    Output:\n",
    "    out: shape=(BS,N,B,1)\n",
    "    \"\"\"\n",
    "    # sort of a workaround\n",
    "    Z = torch.arange(B).view(*torch.ones(len(X.shape), dtype=int), B).expand(*X.shape, -1).to(device)\n",
    "    X = X.view(*X.shape, 1).expand(*X.shape, B)\n",
    "    I = I.view(*I.shape, 1).expand(*I.shape, B)\n",
    "    \n",
    "    assert X.shape == I.shape == Z.shape\n",
    "    \n",
    "    ll_i = model_i._log_likelihood(I, X, Z) #shape = (BS,N,B)\n",
    "    ll_h = model_h._log_likelihood(H) #shape=(BS,N,B,H_dim)\n",
    "    # print(ll_i.shape, ll_h.shape)\n",
    "    \n",
    "    out = (ll_i + ll_h.sum(-1)).unsqueeze(-1) #shape for each = (BS,N,B)\n",
    "    return out #shape for each = (BS,N,B,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def l_n_vectorized_paper(I, Y, X, H, B, model_i, model_h, model_y, device):\n",
    "    \"\"\"\n",
    "    I: shape=(BS,N)\n",
    "    Y: shape=(BS,N)\n",
    "    X: shape=(BS,N)\n",
    "    H: shape=(BS,N,H_dim)\n",
    "    device: 'cuda'/'cpu'\n",
    "\n",
    "    Output:\n",
    "    out: shape=(BS,N,B,1)\n",
    "    \"\"\"\n",
    "    # sort of a workaround\n",
    "    Z = torch.arange(B).view(*torch.ones(len(X.shape), dtype=int), B).expand(*X.shape, -1).to(device)\n",
    "    X = X.view(*X.shape, 1).expand(*X.shape, B)\n",
    "    I = I.view(*I.shape, 1).expand(*I.shape, B)\n",
    "    \n",
    "    assert X.shape == I.shape == Z.shape\n",
    "    \n",
    "    ll_i = model_i._log_likelihood(I, X, Z) #shape = (BS,N,B)\n",
    "    ll_h = model_h._log_likelihood(H) #shape=(BS,N,B,H_dim)\n",
    "    ll_y = model_y._log_likelihood(H, Y) #shape(BS,N,Y_dim)\n",
    "    \n",
    "    # print(ll_i.shape, ll_h.shape)\n",
    "    \n",
    "    out = (ll_i + ll_h.sum(-1) + ll_y.sum(-1).unsqueeze(-1)).unsqueeze(-1) #shape for each = (BS,N,B)\n",
    "    return out #shape for each = (BS,N,B,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\psi_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def psi_n_vectorized(X, model_z):\n",
    "    \"\"\"\n",
    "    X: shape=(BS,N)\n",
    "    \"\"\"\n",
    "    init_shape = X.shape\n",
    "    X_mod = model_z.transform_x(X) #shape = (BS,N,B)\n",
    "    X_mod = X_mod.unsqueeze(-2) #shape = (BS,N,1,B) - make 'row vector'\n",
    "\n",
    "    unnorm_logits = model_z.P.view(1,1,*model_z.P.shape) + X_mod #shape = (1,1,B,B) + (BS,N,1,B) = (BS,N,B,B)\n",
    "    normalizer = torch.logsumexp(unnorm_logits, dim=-1, keepdim=True) #shape = (BS,N,B,1)\n",
    "    return (unnorm_logits - normalizer) #shape=(BS,N,B,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $m_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_message(psi_matrix, l_vector, prev_message_vector):\n",
    "    \"\"\"\n",
    "    psi_matrix: shape=(..., B,B)\n",
    "    l_vector: shape=(..., B,1)\n",
    "    prev_message_vector: shape=(..., B,1)\n",
    "\n",
    "    Output: \n",
    "    next_message_vector: shape=(..., B,1)\n",
    "    \"\"\"\n",
    "    raw_messages = psi_matrix + l_vector + prev_message_vector #shape=(..., B, B)\n",
    "    next_message_vector = torch.logsumexp(raw_messages, dim=-2, keepdim=True) #shape=(..., 1, B) - 'row vector'\n",
    "    next_message_vector = next_message_vector.transpose(-1,-2)\n",
    "\n",
    "    #Alternate way of doing above two steps in one\n",
    "    # _next_message_vector = torch.logsumexp(raw_messages, dim=-2, keepdim=False).unsqueeze(-1)\n",
    "    # print((next_message_vector - _next_message_vector).sum())\n",
    "\n",
    "    return next_message_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_message_paper(psi_matrix, l_vector, prev_message_vector):\n",
    "    \"\"\"\n",
    "    psi_matrix: shape=(..., B,B)\n",
    "    l_vector: shape=(..., B,1)\n",
    "    prev_message_vector: shape=(..., B,1)\n",
    "\n",
    "    Output: \n",
    "    next_message_vector: shape=(..., B,1)\n",
    "    \"\"\"\n",
    "    raw_messages = psi_matrix + l_vector + prev_message_vector #shape=(..., B, B)\n",
    "    next_message_vector = torch.logsumexp(raw_messages, dim=-2, keepdim=True) #shape=(..., 1, B) - 'row vector'\n",
    "    next_message_vector = next_message_vector.transpose(-1,-2)\n",
    "\n",
    "    #Alternate way of doing above two steps in one\n",
    "    # _next_message_vector = torch.logsumexp(raw_messages, dim=-2, keepdim=False).unsqueeze(-1)\n",
    "    # print((next_message_vector - _next_message_vector).sum())\n",
    "\n",
    "    return next_message_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def marginalize_z(I,Y,H,X, model_z, model_i, model_h):\n",
    "    \"\"\"\n",
    "    I: shape=(BS,N)\n",
    "    Y: shape=(BS,N,Y_dim)\n",
    "    H: shape=(BS,N,H_dim)\n",
    "    X: shape=(BS,N)\n",
    "    \n",
    "    output:\n",
    "    normalized_factor: shape=(BS,N,1)\n",
    "    \"\"\"\n",
    "    device = I.device\n",
    "    N, S = X.shape\n",
    "    B = model_z.B\n",
    "    psi_matrix = psi_n_vectorized(X, model_z) #shape = (S,N,B,B)\n",
    "    psi_matrix[:,0] *= 0 \n",
    "  \n",
    "    l = l_n_vectorized(I,X,H, B, model_i, model_h, device) #shape = (S,N,B,1)\n",
    "    m = torch.zeros(N,S,B,1).to(device)\n",
    "\n",
    "    m[:,0] += F.log_softmax(model_z.logpi, dim=-1).view(1,B,1) #better way of doing log(pi) - lse(log(pi))? = log(softmax( pi_unnorm ))\n",
    "    for s in range(1,S):\n",
    "        m[:,s] = compute_message(psi_matrix[:,s], l[:,s-1], m[:,s-1])\n",
    "  \n",
    "    normalized_factor = torch.logsumexp(m, dim=-2)\n",
    "    return normalized_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def marginalize_z_paper(I,Y,H,X, model_z, model_i, model_h, model_y):\n",
    "    \"\"\"\n",
    "    I: shape=(BS,N)\n",
    "    Y: shape=(BS,N,Y_dim)\n",
    "    H: shape=(BS,N,H_dim)\n",
    "    X: shape=(BS,N)\n",
    "    \n",
    "    output:\n",
    "    normalized_factor: shape=(BS,N,1)\n",
    "    \"\"\"\n",
    "    device = I.device\n",
    "    N, S = X.shape\n",
    "    B = model_z.B\n",
    "    psi_matrix = psi_n_vectorized(X, model_z) #shape = (S,N,B,B)\n",
    "    psi_matrix[:,0] *= 0 \n",
    "  \n",
    "    l = l_n_vectorized_paper(I,Y,X,H, B, model_i, model_h, model_y, device) #shape = (S,N,B,1)\n",
    "    m = torch.zeros(N,S,B,1).to(device)\n",
    "\n",
    "    m[:,0] += F.log_softmax(model_z.logpi, dim=-1).view(1,B,1) #better way of doing log(pi) - lse(log(pi))? = log(softmax( pi_unnorm ))\n",
    "    for s in range(1,S):\n",
    "        m[:,s] = compute_message(psi_matrix[:,s], l[:,s-1], m[:,s-1])\n",
    "  \n",
    "    normalized_factor = torch.logsumexp(m, dim=-2)\n",
    "    return normalized_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11, 1])\n"
     ]
    }
   ],
   "source": [
    "from pp_lvm.simulations import TrueParameters, simulate_data\n",
    "Params = TrueParameters(S=10, N=11, B=3, H_dim=2, Y_dim=2)\n",
    "I,Y,T,X,Z,H = simulate_data(Params)\n",
    "device='cuda'\n",
    "model_z = Model_z(Params.B).to(device)\n",
    "model_i = Decoder_i(1, Params.B).to(device)\n",
    "model_h = Decoder_h(Params.B, Params.H_dim).to(device)\n",
    "model_y = Decoder_y(Params.H_dim, Params.Y_dim).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(marginalize_z_paper(I,Y,H,X, model_z, model_i, model_h, model_y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_h.mu.weight.flatten().cpu().data); plt.show();\n",
    "plt.hist(model_h.sigma.weight.flatten().cpu().data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_simulations.ipynb.\n",
      "Converted 02_models.ipynb.\n",
      "Converted 03_GP.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
